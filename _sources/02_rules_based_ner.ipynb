{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Custom Named Entity Recognition for Holocaust Documents</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Part 02.01:</center><br><center>Rules-Based NER with spaCy</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Dr. W.J.B. Mattingly</center>\n",
    "\n",
    "<center>Smithsonian Data Science Lab and United States Holocaust Memorial Museum</center>\n",
    "\n",
    "<center>January 2021</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Concepts in this Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Rules-based NER<br>\n",
    "2) gazatteer<br>\n",
    "2) When to use rules-based NER<br>\n",
    "3) The benefits and limitations of rules-based NER<br>\n",
    "4) SpaCy's EntityRuler<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Rules-Based NER?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I mentioned in the previous notebook, there are two types of NLP and NER: rules-based and machine learning-based. This notebook will be dedicated to rules-based, while the next one will be dedicated to machine learning-based.\n",
    "\n",
    "Rules-based NER is the method by which an NLP practitioner either creates or utalizes an NLP system that has a predefined set of instructions, or rules, to perform certain NLP tasks. For NER, this often times means using what is known as a gazatteer. A **gazatteer** is a list, or dictionary, of entities that align with a specific label. In the case of people, this would be a list of first and last names. If you are developing an NER for a specific region, as we will in a later notebook, this may be a list of all locations in that region.\n",
    "\n",
    "Well-cultivated gazatteers served as the primary method for performing NER in the early twenty-first century. It is still a staple in some NLP frameworks, such as v.0.01 of the Classical Language Toolkit (CLTK), which is currently being replaced with machine learning models.\n",
    "\n",
    "Sometimes, however, a researcher may not have a list of all potential names in a domain. In these instances, should one wish to pursue rules-based NLP, one would utalize pattern rules-based NER. In this scenario, the researcher creates a specific set of patterns to find and then presume that anything that aligns with that pattern is a specific entity. This can be used for places, i.e. Berlin, Germany; London, England, Dallas, Texas. In this scenario, one could use string pattern libraries, such as RegEx (Regular Expressions) to find instances of a capitalized word, followed by a comma, followed by another capitalized word and presume that such an occurence is a PLACE. More commonly, however, such a method is used to find dates in a text. While there are many ways to represent a date, there are a limited number of patterns. For example, were I to want to represent January 1st, I could write the following:\n",
    "\n",
    "1) Jan 1<br>\n",
    "2) 1 Jan<br>\n",
    "3) Jan first<br>\n",
    "4) Jan 1st<br>\n",
    "5) January 1st<br>\n",
    "6) January 1<br>\n",
    "7) 1 January<br>\n",
    "\n",
    "There are likely other potential variations, but my point is that there is a limited number of ways of representing a date. For this reason, finding and extraction temporal entities in texts is usually fairly easy via rules-based pattern methods. The problem becomes even easier if dates are only represented a few ways. One could develop a pattern to find any instance of a number, followed by a capital word or visa versa as a date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Bother with Rules-Based NER?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I mentioned in the previous notebook that NLP is moving away from rules-based methods and toward machine learning-based ones. You may be thinking, why you should learn rules-based NLP and NER.\n",
    "\n",
    "The answer is because there remain certain situations in which a rules-based solution is better than a machine learning-based one. Further, there are times when a combination of the two is more suited. In order to understand *when* to use which solution is important and, therefore, a firm foundation in rules-based NER is essential in order to do machine learning NER."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When to Use Rules-Based NER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This raises an important question. *When should you use a rules-based NER approach?* The answer is simple. When there are a finite number of ways a specific entity will be represented so that you can catch roughly 95-97% of them with such rules. I say 95-97% not because this is the industry standard, rather because this is my goal for my NER models. If I can use a rules-based approach and achieve equal accuracy as an ML model, I will likely do that because the time it takes to implement a rules-based approach to NER is often less than the time it takes to train, validate, and test a machine learning model.\n",
    "\n",
    "As we will see in the video below, this is a particularly useful approach when you know every potential name in a corpus, such as we will see with the toy example of Harry Potter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Limitations of Rules-Based NER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A key thing to remember, however, is that rules-based methods are precisely that: rules-based. If an entity falls outside of the rule you have developed, then it will not be flagged as an entity. This is particularly prevenlant in texts that have been OCRed, typed without spellcheck, unedited, or any form of uncleaned text.\n",
    "\n",
    "While cleaning texts is an essential component to proper data preparation for NLP, it is sometimes impossible to clean entirely a text and, sometimes, an individual using your particular NER framework may not know to clean texts before hand. This is the chief limitation of rules-based methods and it is one of the chief reasons researchers use machine learning methods today. Machine learning models learn and can, therefore, generalize on unseen data, despite variance (to an extent) from things it has seen in the past. We will explore this in greater detail in the next notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SpaCy's EntityRuler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While spaCy is chiefly a machine learning NLP library, it possess the ability to use rules-based NER methods. This is a major strength of the library, for as we shall see to develop a strong NER system for many difficult domains, a combination of rules-based and machine learning-based approaches are sometimes essential.\n",
    "\n",
    "There are a few ways to engage in rules-based NER with spaCy, but one of the more fundamental is its EntityRuler.\n",
    "\n",
    "Let's return to our sample sentence from the first notebook with Martha the basketball player. In this scenario, we want to not only extract the normal entities from the text (PERSON, DATE, etc.), but also a new entity SPORT. In a later notebook, we will discuss adding custom entities in much more detail. For now, we will use this simple toy example to demonstrate how rules-based NER works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basketball SPORT\n"
     ]
    }
   ],
   "source": [
    "text = \"Martha, a senior, moved to Spain where she will be playing basketball until 05 June 2022 or until she can't play any longer.\"\n",
    "\n",
    "#Import spacy\n",
    "import spacy\n",
    "\n",
    "\n",
    "#Create a blank spaCy model that will parse English (\"en\")\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "\n",
    "#Create a ruler that we will add to the model\n",
    "ruler = nlp.create_pipe(\"entity_ruler\")\n",
    "\n",
    "\n",
    "#Develop a pattern to find\n",
    "ruler.add_patterns([{\"label\": \"SPORT\", \"pattern\": \"basketball\"}])\n",
    "\n",
    "#Add the ruler with the new pattern its it knowledge-base to the model\n",
    "nlp.add_pipe(ruler)\n",
    "\n",
    "#Create the doc object by processing the text through our newly created nlp model\n",
    "doc = nlp(text)\n",
    "\n",
    "#Iterate over all entities (there will be only one)\n",
    "for ent in doc.ents:\n",
    "    print (ent.text, ent.label_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the output is as desired. We have extracted basektball, the string, and its correct label, SPORT. Don't be alarmed if you don't entirely understand how the code above works. By the end of this series, you will. For now, simply understand *how* rules-based NER works. Expirement with the code above and try to create a model below that can identify soccer as a SPORT in the following text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Scott enjoys to play soccer.\"\n",
    "\n",
    "\n",
    "#Here, replicate the code above to find soccer as a SPORT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video for Rules-Based NER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you've finished with the above exercise, check out the video on Rules-Based NER below. It reinforces some of these concepts and explores them in a larger context, specifically via the first book of Harry Potter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div align=\"center\">\n",
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/O_2uq0sdCQo\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<div align=\"center\">\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/O_2uq0sdCQo\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
