
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>4. Machine Learning NER with spaCy &#8212; Introduction to Named Entity Recognition</title>
    
  <link rel="stylesheet" href="_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="1. Using SpaCy’s EntityRuler" href="04_01_spaCy_Entity_Ruler.html" />
    <link rel="prev" title="3. Rules-Based NER with spaCy" href="02_rules_based_ner.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="index.html">
  
  <img src="_static/data_science_lab_logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Introduction to Named Entity Recognition</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="intro.html">
   <p align="center">
    INTRODUCTION TO NAMED ENTITY RECOGNITION
   </p>
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Key Concepts and Terms
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="01_01_introduction_to_ner.html">
   1. Introduction to Named Entity Recognition
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="01_02_introduction_to_spacy.html">
   2. Introduction to spaCy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="02_rules_based_ner.html">
   3. Rules-Based NER with spaCy
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   4. Machine Learning NER with spaCy
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  The Basics of NER Training
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="04_01_spaCy_Entity_Ruler.html">
   1. Using SpaCy's EntityRuler
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="04_02_create_ner_training_set.html">
   2. Using EntityRuler to Create Training Set
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="04_03_train_spacy_ner_model.html">
   3. How to Train spaCy NER Model
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Advanced NER Concepts
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="05_examining_a_spacy_model.html">
   1. Examining a spaCy Model in the Folder
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="06_introduction_to_word_vectors.html">
   2. Introduction to Word Vectors
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="07_generating_custom_word_vectors.html">
   3. Generating Custom Word Vectors with Gensim
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="08_loading_custom_word_vectors.html">
   4. Loading Custom Word Vectors into a spaCy Model
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Solving a Domain-Specific Problem (Holocaust)
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="09_01_cultivating_concentration_camp_dataset.html">
   1. Cultivating Good Datasets for Entities
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="09_02_cultivating_corpus.html">
   2. Cultivating a Corpus
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="10_the_challenges_of_holocaust_ner.html">
   3. The Challenges of Holocaust NER
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="11_introduction_to_custom_pipes.html">
   4. Introduction to Custom Pipes
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/03_machine_learning_ner.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/wjbmattingly/holocaust_ner_lessons"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/wjbmattingly/holocaust_ner_lessons/issues/new?title=Issue%20on%20page%20%2F03_machine_learning_ner.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        <a class="edit-button" href="https://github.com/wjbmattingly/holocaust_ner_lessons/edit/main/03_machine_learning_ner.ipynb"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/wjbmattingly/holocaust_ner_lessons/main?urlpath=tree/03_machine_learning_ner.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#key-concepts-in-this-notebook">
   4.1. Key Concepts in this Notebook
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#what-is-machine-learning">
   4.2. What is Machine Learning?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#types-of-machine-learning">
   4.3. Types of Machine Learning
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#supervised-learning-in-ner">
   4.4. Supervised Learning in NER
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#how-does-supervised-learning-work-math-alert">
   4.5. How does Supervised Learning Work? (MATH ALERT!)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#when-to-use-machine-learning-ner">
   4.6. When to use Machine Learning NER
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#using-spacy-s-machine-learning-models">
   4.7. Using spaCy’s Machine Learning Models
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exercise">
   4.8. Exercise
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#video-for-machine-learning-ner">
   4.9. Video for Machine Learning NER
  </a>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="center-machine-learning-ner-with-spacy-center">
<h1><span class="section-number">4. </span><center>Machine Learning NER with spaCy</center><a class="headerlink" href="#center-machine-learning-ner-with-spacy-center" title="Permalink to this headline">¶</a></h1>
<center>Dr. W.J.B. Mattingly</center>
<center>Smithsonian Data Science Lab and United States Holocaust Memorial Museum</center>
<center>January 2021</center><div class="section" id="key-concepts-in-this-notebook">
<h2><span class="section-number">4.1. </span>Key Concepts in this Notebook<a class="headerlink" href="#key-concepts-in-this-notebook" title="Permalink to this headline">¶</a></h2>
<ol class="simple">
<li><p>Machine Learning<br></p></li>
<li><p>Statistics<br></p></li>
<li><p>Linear Algebra<br></p></li>
<li><p>Matrix (pl. Matrices)<br></p></li>
<li><p>Vectors<br></p></li>
<li><p>Tensors<br></p></li>
<li><p>Word Embeddings (Word Vectors)<br></p></li>
<li><p>Machine Learning Training, Validation, and Testing<br></p></li>
<li><p>spaCy models<br></p></li>
</ol>
</div>
<div class="section" id="what-is-machine-learning">
<h2><span class="section-number">4.2. </span>What is Machine Learning?<a class="headerlink" href="#what-is-machine-learning" title="Permalink to this headline">¶</a></h2>
<p><strong>Machine learning</strong> is a branch of Artificial Intelligence. In order to understand artifical intelligence and how modern machine learning is different from its predecessor, I would recomend my video on the subject (a brief cinematic introduction to machine learning from my series on Machine Learning for DH.)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%html</span>
<span class="p">&lt;</span><span class="nt">div</span> <span class="na">align</span><span class="o">=</span><span class="s">&quot;center&quot;</span><span class="p">&gt;</span>
<span class="p">&lt;</span><span class="nt">iframe</span> <span class="na">width</span><span class="o">=</span><span class="s">&quot;560&quot;</span> <span class="na">height</span><span class="o">=</span><span class="s">&quot;315&quot;</span> <span class="na">src</span><span class="o">=</span><span class="s">&quot;https://www.youtube.com/embed/G6cW5JybUPU&quot;</span> <span class="na">frameborder</span><span class="o">=</span><span class="s">&quot;0&quot;</span> <span class="na">allow</span><span class="o">=</span><span class="s">&quot;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture&quot;</span> <span class="na">allowfullscreen</span><span class="p">&gt;&lt;/</span><span class="nt">iframe</span><span class="p">&gt;</span>
<span class="p">&lt;/</span><span class="nt">div</span><span class="p">&gt;</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div align="center">
<iframe width="560" height="315" src="https://www.youtube.com/embed/G6cW5JybUPU" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div>
</div></div>
</div>
<p>Machine Learning (and deep learning) is the process by which practitioners teach a computer system to perform a task, not with rules, but with statistics and linear algebra so that the system can learn from repeated (and randomized) experiences. If this does not make sense right now, it will by the end of this notebook. This notebook will necessary contain some math, but it will be kept to an absolute minimum. I will only present the math and mathematical concepts that are absolutely necessary.</p>
<p>Before moving forward, I also recommend this brief video on deep learning from my series on Neural Networks for DH.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%html</span>
<span class="p">&lt;</span><span class="nt">div</span> <span class="na">align</span><span class="o">=</span><span class="s">&quot;center&quot;</span><span class="p">&gt;</span>
<span class="p">&lt;</span><span class="nt">iframe</span> <span class="na">width</span><span class="o">=</span><span class="s">&quot;560&quot;</span> <span class="na">height</span><span class="o">=</span><span class="s">&quot;315&quot;</span> <span class="na">src</span><span class="o">=</span><span class="s">&quot;https://www.youtube.com/embed/G0hvxnb7hHM&quot;</span> <span class="na">frameborder</span><span class="o">=</span><span class="s">&quot;0&quot;</span> <span class="na">allow</span><span class="o">=</span><span class="s">&quot;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture&quot;</span> <span class="na">allowfullscreen</span><span class="p">&gt;&lt;/</span><span class="nt">iframe</span><span class="p">&gt;</span>
<span class="p">&lt;/</span><span class="nt">div</span><span class="p">&gt;</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div align="center">
<iframe width="560" height="315" src="https://www.youtube.com/embed/G0hvxnb7hHM" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div>
</div></div>
</div>
</div>
<div class="section" id="types-of-machine-learning">
<h2><span class="section-number">4.3. </span>Types of Machine Learning<a class="headerlink" href="#types-of-machine-learning" title="Permalink to this headline">¶</a></h2>
<p>There are several different types of machine learning: supervised learning, unsupervised learning, and semi-supervised learning. There are others (such as reinforcement learning), but these are the three essential forms.</p>
<p><strong>Supervised learning</strong> is when we train a system with known data. In the case of NER, we train a system with a series of texts with the entities appropriately annotated with their corresponding labels. <strong>Unsupervised learning</strong> occurs when you don’t know the categories of your data. You give the system a series of data and allow it to learn and identify patterns on its own. This is most popularly used for topic modeling and k-means (beyond the scope of this notebook). Finally, there is <strong>semi-supervised learning</strong> which falls between these two.</p>
<p>Throughout this series, we will be using supervised learning and for that reason, I would like to explain this process from start to finish and then explain how it works.</p>
</div>
<div class="section" id="supervised-learning-in-ner">
<h2><span class="section-number">4.4. </span>Supervised Learning in NER<a class="headerlink" href="#supervised-learning-in-ner" title="Permalink to this headline">¶</a></h2>
<p>As noted above, supervised learning is the process by which a system learns from a set of inputs that have known labels. In order to train properly, the input data is divided into three categories: training data, validation data, and testing data. There is no set percentage to asign to each of these categories. A good rule of thumb, however, is save 20% of all annotated data for testing and then divide the remaining 80% 80/20 (testing/validation) ratio.</p>
<p>The first two, training data and validation data, are given to the system that is trying to learn. It uses the training data to hone a statistical model via predetermined algorithms. It does this by making guesses about what the proper labels are. It then checks its accuracy against the labels provided and makes adjustments accordingly.</p>
<p>Once it is finished viewing and guessing across all the training data, the first epoch, or iteration over the data, is finished. At this stage, the model then tests its accuracy against the validation data. These are left out of the training process and give the system a sense of its overall performance.</p>
<p>Because the validation data is left out of the training process, it able to be used for mid-training testing (or validation) of its accuracy. The training data is then randomized and given back to the system for x number of epochs. Again, there is no standard for the number of epochs, but a good rule of thumb is to start at 10 and study the results.</p>
<p>Once the model repeats this process for the set number of epochs, it is finished training. The model’s accuracy can then be tested against the testing dataset to see how well it performs. The reason you want to keep the testing data separate from the validation data is because, despite being not include in the training, some of the validation data seeps into the training process. Because the testing data is well-annotated, the researcher can get an accurate sense of how well that model performs.</p>
<p>With that first model saved, it is common practice to adjust the parameters of the model multiple times to try to create a more accurate model. All models will be tested against the same testing data.</p>
<p>At this stage, depending on the results, more training data may need to be obtained, another test may be called for, or the researcher can begin deploying the model on unseen data and examine the results. Unseen data will be data that does not have annotations.</p>
<p>A good way to describe it is via the image below from https://bigdata-madesimple.com/. In the image, we see the input of raw data to an algorithm.</p>
<img alt="https://bigdata-madesimple.com/wp-content/uploads/2018/02/Machine-Learning-Explained1.png" src="https://bigdata-madesimple.com/wp-content/uploads/2018/02/Machine-Learning-Explained1.png" />
</div>
<div class="section" id="how-does-supervised-learning-work-math-alert">
<h2><span class="section-number">4.5. </span>How does Supervised Learning Work? (MATH ALERT!)<a class="headerlink" href="#how-does-supervised-learning-work-math-alert" title="Permalink to this headline">¶</a></h2>
<p>As the heading indicates, this section will venture into the realm of math, specifically statistics and linear algebra. Even if you are not a fan of math, please do read this section as it contains the foundational principals behind machine learning. I will keep the math to a minimum in order to simply explain <em>how</em> machine learning works and, even more importantly <em>why</em>. This will give you a better sense of not only when to use a machine learning approach to NER, but why you might not get the results you want to see and how to improve them.</p>
<p>The core concept behind supervised learning is the statistical model, a saved and usable system that can be given an input (a text) and output some sort of structured data (labels for entities). In order to understand what models are and how they work, I recommend watching the brief video below:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%html</span>
<span class="p">&lt;</span><span class="nt">div</span> <span class="na">align</span><span class="o">=</span><span class="s">&quot;center&quot;</span><span class="p">&gt;</span>
<span class="p">&lt;</span><span class="nt">iframe</span> <span class="na">width</span><span class="o">=</span><span class="s">&quot;560&quot;</span> <span class="na">height</span><span class="o">=</span><span class="s">&quot;315&quot;</span> <span class="na">src</span><span class="o">=</span><span class="s">&quot;https://www.youtube.com/embed/I9Nl8QIIP54&quot;</span> <span class="na">frameborder</span><span class="o">=</span><span class="s">&quot;0&quot;</span> <span class="na">allow</span><span class="o">=</span><span class="s">&quot;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture&quot;</span> <span class="na">allowfullscreen</span><span class="p">&gt;&lt;/</span><span class="nt">iframe</span><span class="p">&gt;</span>
<span class="p">&lt;/</span><span class="nt">div</span><span class="p">&gt;</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div align="center">
<iframe width="560" height="315" src="https://www.youtube.com/embed/I9Nl8QIIP54" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div>
</div></div>
</div>
<p>Through spaCy, NLP practitioners do not have to engage in the tedious structure of neural networks. Instead, they can take advantage of the state-of-the-art neural network architectures developed by spaCy and easily train spaCy models with just a few lines of code. If you are curious about how training works, I recommend the video below:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%html</span>
<span class="p">&lt;</span><span class="nt">div</span> <span class="na">align</span><span class="o">=</span><span class="s">&quot;center&quot;</span><span class="p">&gt;</span>
<span class="p">&lt;</span><span class="nt">iframe</span> <span class="na">width</span><span class="o">=</span><span class="s">&quot;560&quot;</span> <span class="na">height</span><span class="o">=</span><span class="s">&quot;315&quot;</span> <span class="na">src</span><span class="o">=</span><span class="s">&quot;https://www.youtube.com/embed/s8yQ4lRrEIY&quot;</span> <span class="na">frameborder</span><span class="o">=</span><span class="s">&quot;0&quot;</span> <span class="na">allow</span><span class="o">=</span><span class="s">&quot;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture&quot;</span> <span class="na">allowfullscreen</span><span class="p">&gt;&lt;/</span><span class="nt">iframe</span><span class="p">&gt;</span>
<span class="p">&lt;/</span><span class="nt">div</span><span class="p">&gt;</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div align="center">
<iframe width="560" height="315" src="https://www.youtube.com/embed/s8yQ4lRrEIY" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div>
</div></div>
</div>
</div>
<div class="section" id="when-to-use-machine-learning-ner">
<h2><span class="section-number">4.6. </span>When to use Machine Learning NER<a class="headerlink" href="#when-to-use-machine-learning-ner" title="Permalink to this headline">¶</a></h2>
<p>In the last notebook, I explained when to use rules-based NER. Machine learning NER is useful when you cannot possible account for all variances of the entities in a corpus or creating such patterns would be so computationally expensive that its accuracy is not worth its use. A good example of this is every potential variation of a person’s name. Consider the immense quantity of names that exist in the world and the combinations and various ways those names can be combined to create a unique entity. Even if we only have 10,000 first names and 10,000 last names, to account for all variations would be 100,000,000 million patterns to match. And there are far more than simple 10,000 of each in the world.</p>
<p>Another time to consider machine learning is when the data that will be fed to your system will not be entirely cleaned. Consider the example of names once again. Even if you had a system that could account for all 100,000,000 forms of those names, it will miss ones that have poor OCR or ones that have different text encoding because it was a text created prior to UTF-8.</p>
<p>In these instances machine learning is the right choice because machine learning NER models do not memorize entities. They learn entities. This means that if a model encounters an entity it has never seen before (even if poorly OCRed), it has the ability to <strong>generalize</strong> and identify that entity with the correct label.</p>
</div>
<div class="section" id="using-spacy-s-machine-learning-models">
<h2><span class="section-number">4.7. </span>Using spaCy’s Machine Learning Models<a class="headerlink" href="#using-spacy-s-machine-learning-models" title="Permalink to this headline">¶</a></h2>
<p>Fortunately, as we will see in this series, spaCy makes not only using machine learning models easy, but drastically reduces the complexity of training custom machine learning NER models.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#We import the necessary library</span>
<span class="kn">import</span> <span class="nn">spacy</span>

<span class="c1">#load the machine learning model</span>
<span class="n">nlp</span> <span class="o">=</span> <span class="n">spacy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;en_core_web_sm&quot;</span><span class="p">)</span>

<span class="c1">#create a sample text</span>
<span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;Jon Stewart hosted The Daily Show that aired in New York City.&quot;</span>

<span class="c1">#create the spaCy doc</span>
<span class="n">doc</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>

<span class="c1">#extract all the entities from the doc with their labels</span>
<span class="k">for</span> <span class="n">ent</span> <span class="ow">in</span> <span class="n">doc</span><span class="o">.</span><span class="n">ents</span><span class="p">:</span>
    <span class="nb">print</span> <span class="p">(</span><span class="n">ent</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="n">ent</span><span class="o">.</span><span class="n">label_</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Jon Stewart PERSON
The Daily Show WORK_OF_ART
New York City GPE
</pre></div>
</div>
</div>
</div>
<p>In the example above, we seethe small English model Correctly identify John Stewart as a person. It identified The Daily Show as a WORK_OF_ART which is interesting and arguably true. Finally, it correctly identified New York City as a GPE (Geopolitical Entity). Now, let’s introduce some textual problems to see how the model performs.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#We import the necessary library</span>
<span class="kn">import</span> <span class="nn">spacy</span>

<span class="c1">#load the machine learning model</span>
<span class="n">nlp</span> <span class="o">=</span> <span class="n">spacy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;en_core_web_sm&quot;</span><span class="p">)</span>

<span class="c1">#create a sample text</span>
<span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;Jon Stewwasrt hosted The Daily Show that aired in New Yasdfasasdfrk City.&quot;</span>

<span class="c1">#create the spaCy doc</span>
<span class="n">doc</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>

<span class="c1">#extract all the entities from the doc with their labels</span>
<span class="k">for</span> <span class="n">ent</span> <span class="ow">in</span> <span class="n">doc</span><span class="o">.</span><span class="n">ents</span><span class="p">:</span>
    <span class="nb">print</span> <span class="p">(</span><span class="n">ent</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="n">ent</span><span class="o">.</span><span class="n">label_</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Jon Stewwasrt PERSON
The Daily Show WORK_OF_ART
New Yasdfasasdfrk City GPE
</pre></div>
</div>
</div>
</div>
<p>Notice that despite introducing textual corruption, the model performs precisely the same way. The reason? Because it has learned from context. It has likely seen the word “hosted” before and knows that people typically host. It has seen the word City capitalized often used to describe a GPE. This is why machine learning offers the solution for inconsistent entities or entities that are so vast that incorperating them all into an EntityRuler would be impossible.</p>
</div>
<div class="section" id="exercise">
<h2><span class="section-number">4.8. </span>Exercise<a class="headerlink" href="#exercise" title="Permalink to this headline">¶</a></h2>
<p>In the code space provided below try to push the small English model. Make some guesses based on what you’ve learned why the model either succeeds or fails to identify entities despite the textual corruptions you introduce. As you do this, keep in mind that this is the <em>small</em> model. The larger models perform better for reasons that we will explore later in this series.</p>
</div>
<div class="section" id="video-for-machine-learning-ner">
<h2><span class="section-number">4.9. </span>Video for Machine Learning NER<a class="headerlink" href="#video-for-machine-learning-ner" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%html</span>
<span class="p">&lt;</span><span class="nt">div</span> <span class="na">align</span><span class="o">=</span><span class="s">&quot;center&quot;</span><span class="p">&gt;</span>
<span class="p">&lt;</span><span class="nt">iframe</span> <span class="na">width</span><span class="o">=</span><span class="s">&quot;560&quot;</span> <span class="na">height</span><span class="o">=</span><span class="s">&quot;315&quot;</span> <span class="na">src</span><span class="o">=</span><span class="s">&quot;https://www.youtube.com/embed/2Ny0yATnuxY&quot;</span> <span class="na">frameborder</span><span class="o">=</span><span class="s">&quot;0&quot;</span> <span class="na">allow</span><span class="o">=</span><span class="s">&quot;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture&quot;</span> <span class="na">allowfullscreen</span><span class="p">&gt;&lt;/</span><span class="nt">iframe</span><span class="p">&gt;</span>
<span class="p">&lt;/</span><span class="nt">div</span><span class="p">&gt;</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div align="center">
<iframe width="560" height="315" src="https://www.youtube.com/embed/2Ny0yATnuxY" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div>
</div></div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="02_rules_based_ner.html" title="previous page"><span class="section-number">3. </span><center>Rules-Based NER with spaCy</center></a>
    <a class='right-next' id="next-link" href="04_01_spaCy_Entity_Ruler.html" title="next page"><span class="section-number">1. </span><center>Using SpaCy’s EntityRuler</center></a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By William Mattingly<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="_static/js/index.d3f166471bb80abb5163.js"></script>


    
  </body>
</html>